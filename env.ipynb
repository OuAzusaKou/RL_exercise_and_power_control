{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41621e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-8901ab695d2f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8901ab695d2f>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    self.state=\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class elec_env():\n",
    "    def __init__():\n",
    "        self.reset()\n",
    "    def reset():\n",
    "        self.state="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57714d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculate_state() missing 6 required positional arguments: 'Ppv', 'Pload', 'hload', 'pt', 'pg', and 'soc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c78fd747ae64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: calculate_state() missing 6 required positional arguments: 'Ppv', 'Pload', 'hload', 'pt', 'pg', and 'soc'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Nchp=1\n",
    "Qng=1\n",
    "def calculate_state(Ppv,Pload,hload,pt,pg,soc):\n",
    "    state = np.zeros((1,7))\n",
    "    \n",
    "    Vchp = hload/ ((1-Nchp)*Qng)\n",
    "    \n",
    "    Pchp = Vchp * Qng * Nchp\n",
    "    \n",
    "    M = Ppv + Pchp -Pload\n",
    "    \n",
    "    return state\n",
    "print(calculate_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e390427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dt', 'i', 'm', 'pv', 'pload', 'hload', 'pg', 'pt', 'soc'], dtype='object')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.12, 6.54, 8.15, 9.59, 10.8, 10.88, 10.36, 9.88, 8.06, 6.25, 3.82, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def csv_statis():\n",
    "    df = pd.read_csv('qlearning.csv')\n",
    "    return df\n",
    "df=csv_statis()\n",
    "df.head()\n",
    "print(df.keys())\n",
    "pv=df['pv']\n",
    "\n",
    "print(pv.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9f7246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pload=list(set(df['pload'].tolist()))\n",
    "hload=set(df['hload'].tolist())\n",
    "pg=df['pg'].tolist()\n",
    "pt=df['pt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3881d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pv     pload     hload    pg    pt\n",
      "0    0.00  2.842833  0.516879  0.33  0.42\n",
      "1    0.00  4.186167  0.761121  0.33  0.42\n",
      "2    0.00  4.316667  0.784848  0.33  0.42\n",
      "3    0.00  2.842833  0.516879  0.33  0.42\n",
      "4    0.00  3.852000  0.700364  0.33  0.42\n",
      "5    0.00  4.325167  0.786394  0.33  0.42\n",
      "6    0.00  2.829333  0.514424  0.33  0.42\n",
      "7    2.12  2.811333  0.511152  0.33  0.42\n",
      "8    6.54  2.795667  0.508303  0.33  0.87\n",
      "9    8.15  2.802167  0.509485  0.33  0.87\n",
      "10   9.59  4.187500  0.761364  0.33  0.87\n",
      "11  10.80  2.871167  0.522030  0.33  1.35\n",
      "12  10.88  2.832667  0.515030  0.33  1.35\n",
      "13  10.36  3.002500  0.545909  0.33  1.35\n",
      "14   9.88  2.817000  0.512182  0.33  1.35\n",
      "15   8.06  2.286833  0.415788  0.33  1.35\n",
      "16   6.25  3.753667  0.682485  0.33  0.87\n",
      "17   3.82  2.361333  0.429333  0.33  0.87\n",
      "18   0.00  2.340333  0.425515  0.33  1.35\n",
      "19   0.00  2.260000  0.410909  0.33  1.35\n",
      "20   0.00  3.617167  0.657667  0.33  1.35\n",
      "21   0.00  3.715000  0.675455  0.33  1.35\n",
      "22   0.00  2.297167  0.417667  0.33  0.87\n",
      "23   0.00  3.108500  0.565182  0.33  0.87\n",
      "P_pv [ 0.    0.    0.    0.    0.    0.    0.    2.12  6.54  8.15  9.59 10.8\n",
      " 10.88 10.36  9.88  8.06  6.25  3.82  0.    0.    0.    0.    0.    0.  ]\n",
      "P_load [2.84283333 4.18616667 4.31666667 2.84283333 3.852      4.32516667\n",
      " 2.82933333 2.81133333 2.79566667 2.80216667 4.1875     2.87116667\n",
      " 2.83266667 3.0025     2.817      2.28683333 3.75366667 2.36133333\n",
      " 2.34033333 2.26       3.61716667 3.715      2.29716667 3.1085    ]\n",
      "H_load [0.51687879 0.76112121 0.78484849 0.51687879 0.70036364 0.78639394\n",
      " 0.51442424 0.51115151 0.50830303 0.50948485 0.76136364 0.5220303\n",
      " 0.5150303  0.54590909 0.51218182 0.41578788 0.68248485 0.42933333\n",
      " 0.42551515 0.41090909 0.65766667 0.67545455 0.41766667 0.56518182]\n",
      "P [0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.87 0.87 0.87 1.35 1.35 1.35\n",
      " 1.35 1.35 0.87 0.87 1.35 1.35 1.35 1.35 0.87 0.87]\n",
      "P_g [0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33\n",
      " 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33]\n",
      "V_chp [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "colos=['pv','pload','hload','pg','pt']\n",
    "state_=df[colos]\n",
    "print(state_)\n",
    "P_pv = df['pv']\n",
    "P_pv = np.array(P_pv.tolist())\n",
    "print('P_pv',P_pv)\n",
    "P_load = df['pload']\n",
    "P_load = np.array(P_load.tolist())\n",
    "print('P_load',P_load)\n",
    "H_load = df['hload']\n",
    "H_load = np.array(H_load.tolist())\n",
    "print('H_load',H_load)\n",
    "P = df['pt']\n",
    "P = np.array(P.tolist())\n",
    "print('P',P)\n",
    "P_g = df['pg']\n",
    "P_g = np.array(P_g.tolist())\n",
    "print('P_g',P_g)\n",
    "V_chp = np.zeros((24,))\n",
    "print('V_chp',V_chp)\n",
    "SOC = np.zeros((24,))\n",
    "p_ess = np.zeros((24,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8aec9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "C_cs = 0.1\n",
    "n_chp = 0.5\n",
    "q_NG = 0.5\n",
    "def reset():\n",
    "    state={\n",
    "          'M':0,\n",
    "          'SOC':0,\n",
    "          'P_pv':0,\n",
    "          'P_load':0,\n",
    "          'H_load':0,\n",
    "          'P':0,\n",
    "          'P_g':0,\n",
    "           'T':0\n",
    "    }\n",
    "    \n",
    "    state['SOC'] = random.randint(0,2)*4+3\n",
    "    state['P_pv'] = P_pv[0]\n",
    "    state['P_load'] = P_load[0]\n",
    "    state['H_load'] = H_load[0]\n",
    "    state['P'] = P[0]\n",
    "    state['P_g'] = P_g[0]\n",
    "    \n",
    "    V_chp[0] = H_load[0]/(1 - n_chp)*q_NG\n",
    "    \n",
    "    P_chp = V_chp[0]*q_NG*n_chp\n",
    "\n",
    "    state['M'] = P_pv[0] + P_chp - P_load[0]\n",
    "    \n",
    "    SOC[0] = state['SOC']\n",
    "    \n",
    "    state['T'] = 0\n",
    "    \n",
    "    return str(state)\n",
    "def step(state,action,T):\n",
    "    reward = 0\n",
    "    next_state={\n",
    "      'M':0,\n",
    "      'SOC':0,\n",
    "      'P_pv':0,\n",
    "      'P_load':0,\n",
    "      'H_load':0,\n",
    "      'P':0,\n",
    "      'P_g':0,\n",
    "    'T':0}\n",
    "    \n",
    "    \n",
    "    T=T+1\n",
    "    \n",
    "    \n",
    "    SOC[T] = SOC[T-1] + (action-1)*4\n",
    "    \n",
    "    if SOC[T] > 12:\n",
    "        SOC[T] = 11\n",
    "        reward = reward -100\n",
    "    if SOC[T] < 3:\n",
    "        SOC[T] = 3\n",
    "        reward = reward -100\n",
    "    \n",
    "    V_chp[T] = H_load[T]/(1 - n_chp)*q_NG\n",
    "    \n",
    "    P_chp = V_chp[T]*q_NG*n_chp\n",
    "    \n",
    "    p_ess[T] = (action-1)*4\n",
    "    \n",
    "    M = P_pv[T] + P_chp - P_load[T]\n",
    "    \n",
    "    D = P[T]*M\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        C= P_g[t]*V_chp[t]+C_cs*p_ess[t]\n",
    "    \n",
    "    reward = reward -(C + D)\n",
    "    ################fixed_state##############33\n",
    "    next_state['P_pv'] = P_pv[T]\n",
    "    next_state['P_load'] = P_load[T]\n",
    "    next_state['H_load'] = H_load[T]\n",
    "    next_state['P'] = P[T]\n",
    "    next_state['P_g'] = P_g[T]\n",
    "    ###################################\n",
    "    V_chp[T] = H_load[T]/(1 - n_chp)*q_NG\n",
    "    \n",
    "    P_chp = V_chp[T]*q_NG*n_chp\n",
    "    \n",
    "    next_state['M'] = P_pv[T] + P_chp - P_load[T]\n",
    "    \n",
    "    next_state['SOC'] = SOC[T]\n",
    "    \n",
    "    next_state['T'] = T\n",
    "        \n",
    "    if T==23:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    return reward,str(next_state),T,done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13de535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': -2.713613633181818, 'SOC': 3, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 0}\n"
     ]
    }
   ],
   "source": [
    "state=reset()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b66998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -5.1311679519772735\n",
      "next_state {'M': 5.475204542272728, 'SOC': 11.0, 'P_pv': 8.15, 'P_load': 2.80216667, 'H_load': 0.509484849090909, 'P': 0.87, 'P_g': 0.33, 'T': 9}\n",
      "done False\n"
     ]
    }
   ],
   "source": [
    "reward,next_state,T,done=step(state=state,action=2,T=8)\n",
    "print('reward',reward)\n",
    "print('next_state',next_state)\n",
    "print('done',done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "facb5566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 1.5077022742636366\n",
      "next_state {'M': -3.995886366818182, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 4.18616667, 'H_load': 0.761121212727273, 'P': 0.42, 'P_g': 0.33, 'T': 1}\n",
      "done False\n",
      "reward 1.4794209102272724\n",
      "next_state {'M': -4.1204545486363635, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 4.31666667, 'H_load': 0.784848485454545, 'P': 0.42, 'P_g': 0.33, 'T': 2}\n",
      "done False\n",
      "reward 0.8807177257363636\n",
      "next_state {'M': -2.713613633181818, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 3}\n",
      "done False\n",
      "reward 1.3737318183818181\n",
      "next_state {'M': -3.6769090909090907, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.852, 'H_load': 0.700363636363636, 'P': 0.42, 'P_g': 0.33, 'T': 4}\n",
      "done False\n",
      "reward 1.5028786376999999\n",
      "next_state {'M': -4.128568185, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 4.32516667, 'H_load': 0.78639394, 'P': 0.42, 'P_g': 0.33, 'T': 5}\n",
      "done False\n",
      "reward 0.8747954530090909\n",
      "next_state {'M': -2.7007272695454545, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.82933333, 'H_load': 0.514424241818182, 'P': 0.42, 'P_g': 0.33, 'T': 6}\n",
      "done False\n",
      "reward 0.0669290897727271\n",
      "next_state {'M': -0.5635454513636362, 'SOC': 3.0, 'P_pv': 2.12, 'P_load': 2.81133333, 'H_load': 0.511151514545455, 'P': 0.42, 'P_g': 0.33, 'T': 7}\n",
      "done False\n",
      "reward -3.5368059061227273\n",
      "next_state {'M': 3.8714090877272724, 'SOC': 3.0, 'P_pv': 6.54, 'P_load': 2.79566667, 'H_load': 0.508303030909091, 'P': 0.87, 'P_g': 0.33, 'T': 8}\n",
      "done False\n",
      "reward -4.931167951977273\n",
      "next_state {'M': 5.475204542272728, 'SOC': 3.0, 'P_pv': 8.15, 'P_load': 2.80216667, 'H_load': 0.509484849090909, 'P': 0.87, 'P_g': 0.33, 'T': 9}\n",
      "done False\n",
      "reward -5.03390159110909\n",
      "next_state {'M': 5.592840909090908, 'SOC': 3.0, 'P_pv': 9.59, 'P_load': 4.1875, 'H_load': 0.7613636363636359, 'P': 0.87, 'P_g': 0.33, 'T': 10}\n",
      "done False\n",
      "reward -11.131360222977277\n",
      "next_state {'M': 8.059340905909092, 'SOC': 3.0, 'P_pv': 10.8, 'P_load': 2.87116667, 'H_load': 0.522030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 11}\n",
      "done False\n",
      "reward -11.209992723177274\n",
      "next_state {'M': 8.176090905909092, 'SOC': 3.0, 'P_pv': 10.88, 'P_load': 2.83266667, 'H_load': 0.515030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 12}\n",
      "done False\n",
      "reward -10.28682931838182\n",
      "next_state {'M': 7.493977272727273, 'SOC': 3.0, 'P_pv': 10.36, 'P_load': 3.0025, 'H_load': 0.545909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 13}\n",
      "done False\n",
      "reward -9.888061363636364\n",
      "next_state {'M': 7.1910454545454545, 'SOC': 3.0, 'P_pv': 9.88, 'P_load': 2.8169999999999997, 'H_load': 0.512181818181818, 'P': 1.35, 'P_g': 0.33, 'T': 14}\n",
      "done False\n",
      "reward -8.103123413386363\n",
      "next_state {'M': 5.877113639545454, 'SOC': 3.0, 'P_pv': 8.06, 'P_load': 2.28683333, 'H_load': 0.415787878181818, 'P': 1.35, 'P_g': 0.33, 'T': 15}\n",
      "done False\n",
      "reward -2.4574604515772727\n",
      "next_state {'M': 2.666954542272727, 'SOC': 3.0, 'P_pv': 6.25, 'P_load': 3.75366667, 'H_load': 0.6824848490909089, 'P': 0.87, 'P_g': 0.33, 'T': 16}\n",
      "done False\n",
      "reward -1.5876400029681819\n",
      "next_state {'M': 1.5660000031818182, 'SOC': 3.0, 'P_pv': 3.82, 'P_load': 2.36133333, 'H_load': 0.429333332727273, 'P': 0.87, 'P_g': 0.33, 'T': 17}\n",
      "done False\n",
      "reward 2.8741586322681822\n",
      "next_state {'M': -2.2339545422727274, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.34033333, 'H_load': 0.42551515090909103, 'P': 1.35, 'P_g': 0.33, 'T': 18}\n",
      "done False\n",
      "reward 2.7718981820181816\n",
      "next_state {'M': -2.1572727272727272, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.26, 'H_load': 0.410909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 19}\n",
      "done False\n",
      "reward 4.525612504295455\n",
      "next_state {'M': -3.4527500031818184, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.61716667, 'H_load': 0.657666667272727, 'P': 1.35, 'P_g': 0.33, 'T': 20}\n",
      "done False\n",
      "reward 4.57025409070909\n",
      "next_state {'M': -3.5461363636363634, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.715, 'H_load': 0.6754545454545461, 'P': 1.35, 'P_g': 0.33, 'T': 21}\n",
      "done False\n",
      "reward 1.684792502768182\n",
      "next_state {'M': -2.1927500031818186, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.29716667, 'H_load': 0.41766666727272705, 'P': 0.87, 'P_g': 0.33, 'T': 22}\n",
      "done False\n",
      "reward 2.443637954345454\n",
      "next_state {'M': -2.9672045454545453, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.1085, 'H_load': 0.565181818181818, 'P': 0.87, 'P_g': 0.33, 'T': 23}\n",
      "done True\n",
      "-41.60981316981818\n",
      "{'M': -2.9672045454545453, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.1085, 'H_load': 0.565181818181818, 'P': 0.87, 'P_g': 0.33, 'T': 23}\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "t=0\n",
    "ep_reward = 0\n",
    "state=0\n",
    "while not(done):\n",
    "    reward,state,t,done=step(state=state,action=1,T=t)\n",
    "    print('reward',reward)\n",
    "    print('next_state',str(state))\n",
    "    print('done',done)\n",
    "    ep_reward = ep_reward + reward\n",
    "print(ep_reward)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f2af86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "MAX_ROUND = 3\n",
    "ACT_NUM = 2\n",
    "LR = 0.2\n",
    "class Player:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        return\n",
    "    def reset(self):\n",
    "        reset()\n",
    "        self.greedy = 0.1\n",
    "        return\n",
    "    def behavior_policy(self,Q,state):\n",
    "        sample = np.random.uniform(0, 1)\n",
    "        if sample > self.greedy: \n",
    "            act = np.argmax(Q[state])\n",
    "        else:\n",
    "            act = np.random.randint(0, 3)\n",
    "        return act\n",
    "    def target_policy(self,state,Q):\n",
    "        value = Q[state]\n",
    "        return value\n",
    "    def Qlearning(self,num_episodes, max_time=100, discount_factor=1.0):\n",
    "        Q = defaultdict(lambda:np.zeros(3))\n",
    "        #Q = self.init_Q(Q)\n",
    "        for i_episode in range(1, num_episodes+1):\n",
    "            if i_episode % 1000 == 0:\n",
    "                print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            episode = []\n",
    "            t=0\n",
    "            state=reset()\n",
    "            while(1):\n",
    "                action = self.behavior_policy(Q,state)\n",
    "                #reward,next_state,done = env(action,state)\n",
    "                \n",
    "                reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "\n",
    "                episode.append((state, action, reward))\n",
    "                #print (next_state)\n",
    "                #print('argmax',np.argmax(Q[next_state]),'\\n')\n",
    "                Q[state][action] = Q[state][action] + LR*(reward + discount_factor*Q[next_state][np.argmax(Q[next_state])]-Q[state][action])\n",
    "                state = next_state\n",
    "                t = next_t\n",
    "                if done == True:\n",
    "                    break\n",
    "\n",
    "        print(len(Q))\n",
    "        self.Q=Q\n",
    "        #print(np.argmax(Q[state]))\n",
    "        return self.Q\n",
    "    \n",
    "    def init_Q(self,Q):\n",
    "        for state in range(7):\n",
    "            state = state -3\n",
    "            Q[state]=[0.0,0.0,0.0]\n",
    "        return Q\n",
    "    def simulate(self):\n",
    "        state=reset()\n",
    "        t=0\n",
    "        episode=[]\n",
    "        ep_reward=0\n",
    "        while(1):\n",
    "            action = self.behavior_policy(self.Q,state)\n",
    "            #reward,next_state,done = env(action,state)\n",
    "\n",
    "            reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "            episode.append((action, reward))\n",
    "            state = next_state\n",
    "            t = next_t\n",
    "            ep_reward = ep_reward + reward\n",
    "            if done == True:\n",
    "                break\n",
    "        print('ep_reward',ep_reward)\n",
    "        print('episode',episode)\n",
    "        return ep_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c0e3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 70000/70000.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Player.Qlearning.<locals>.<lambda>()>,\n",
       "            {\"{'M': -2.713613633181818, 'SOC': 3, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 0}\": array([-42.09700925, -42.09555574, -42.14391176]),\n",
       "             \"{'M': -3.995886366818182, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 4.18616667, 'H_load': 0.761121212727273, 'P': 0.42, 'P_g': 0.33, 'T': 1}\": array([-43.61445016, -43.63067086, -43.69519514]),\n",
       "             \"{'M': -4.1204545486363635, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 4.31666667, 'H_load': 0.784848485454545, 'P': 0.42, 'P_g': 0.33, 'T': 2}\": array([-45.05787555, -45.06831056, -45.17030468]),\n",
       "             \"{'M': -2.713613633181818, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 3}\": array([-45.93572362, -45.94300021, -46.07211228]),\n",
       "             \"{'M': -3.6769090909090907, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.852, 'H_load': 0.700363636363636, 'P': 0.42, 'P_g': 0.33, 'T': 4}\": array([-47.32493741, -47.31431741, -47.3975941 ]),\n",
       "             \"{'M': -4.128568185, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 4.32516667, 'H_load': 0.78639394, 'P': 0.42, 'P_g': 0.33, 'T': 5}\": array([-48.83451587, -48.83100035, -48.87627022]),\n",
       "             \"{'M': -2.7007272695454545, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.82933333, 'H_load': 0.514424241818182, 'P': 0.42, 'P_g': 0.33, 'T': 6}\": array([-49.63223946, -49.704283  , -49.77919751]),\n",
       "             \"{'M': -0.5635454513636362, 'SOC': 3.0, 'P_pv': 2.12, 'P_load': 2.81133333, 'H_load': 0.511151514545455, 'P': 0.42, 'P_g': 0.33, 'T': 7}\": array([-49.64476532, -49.70851764, -49.82489915]),\n",
       "             \"{'M': 3.8714090877272724, 'SOC': 3.0, 'P_pv': 6.54, 'P_load': 2.79566667, 'H_load': 0.508303030909091, 'P': 0.87, 'P_g': 0.33, 'T': 8}\": array([-46.11005066, -46.11795044, -46.20980871]),\n",
       "             \"{'M': 5.475204542272728, 'SOC': 3.0, 'P_pv': 8.15, 'P_load': 2.80216667, 'H_load': 0.509484849090909, 'P': 0.87, 'P_g': 0.33, 'T': 9}\": array([-41.1837763 , -41.18375265, -41.29228441]),\n",
       "             \"{'M': 5.592840909090908, 'SOC': 3.0, 'P_pv': 9.59, 'P_load': 4.1875, 'H_load': 0.7613636363636359, 'P': 0.87, 'P_g': 0.33, 'T': 10}\": array([-36.16616364, -36.17667896, -36.17319178]),\n",
       "             \"{'M': 8.059340905909092, 'SOC': 3.0, 'P_pv': 10.8, 'P_load': 2.87116667, 'H_load': 0.522030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 11}\": array([-25.01559259, -24.97714241, -25.06926244]),\n",
       "             \"{'M': 8.176090905909092, 'SOC': 3.0, 'P_pv': 10.88, 'P_load': 2.83266667, 'H_load': 0.515030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 12}\": array([-13.75180977, -13.80910986, -13.86219562]),\n",
       "             \"{'M': 7.493977272727273, 'SOC': 3.0, 'P_pv': 10.36, 'P_load': 3.0025, 'H_load': 0.545909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 13}\": array([-3.36992883, -3.41832256, -3.5429407 ]),\n",
       "             \"{'M': 7.1910454545454545, 'SOC': 3.0, 'P_pv': 9.88, 'P_load': 2.8169999999999997, 'H_load': 0.512181818181818, 'P': 1.35, 'P_g': 0.33, 'T': 14}\": array([6.50256355, 6.37452014, 6.31263516]),\n",
       "             \"{'M': 5.877113639545454, 'SOC': 3.0, 'P_pv': 8.06, 'P_load': 2.28683333, 'H_load': 0.415787878181818, 'P': 1.35, 'P_g': 0.33, 'T': 15}\": array([14.62415219, 14.54922014, 14.4491884 ]),\n",
       "             \"{'M': 2.666954542272727, 'SOC': 3.0, 'P_pv': 6.25, 'P_load': 3.75366667, 'H_load': 0.6824848490909089, 'P': 0.87, 'P_g': 0.33, 'T': 16}\": array([17.04908162, 17.08111186, 16.99022181]),\n",
       "             \"{'M': 1.5660000031818182, 'SOC': 3.0, 'P_pv': 3.82, 'P_load': 2.36133333, 'H_load': 0.429333332727273, 'P': 0.87, 'P_g': 0.33, 'T': 17}\": array([18.6705455 , 18.60503463, 18.54996782]),\n",
       "             \"{'M': -2.2339545422727274, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.34033333, 'H_load': 0.42551515090909103, 'P': 1.35, 'P_g': 0.33, 'T': 18}\": array([15.89764648, 15.81698433, 15.74542441]),\n",
       "             \"{'M': -2.1572727272727272, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.26, 'H_load': 0.410909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 19}\": array([13.12861182, 13.08301896, 12.99197853]),\n",
       "             \"{'M': -3.4527500031818184, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.61716667, 'H_load': 0.657666667272727, 'P': 1.35, 'P_g': 0.33, 'T': 20}\": array([8.58712722, 8.60851102, 8.49472027]),\n",
       "             \"{'M': -3.5461363636363634, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.715, 'H_load': 0.6754545454545461, 'P': 1.35, 'P_g': 0.33, 'T': 21}\": array([4.04238705, 4.01421963, 3.90266041]),\n",
       "             \"{'M': -2.1927500031818186, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 2.29716667, 'H_load': 0.41766666727272705, 'P': 0.87, 'P_g': 0.33, 'T': 22}\": array([2.41445552, 2.44363791, 2.41736063]),\n",
       "             \"{'M': -2.9672045454545453, 'SOC': 3.0, 'P_pv': 0.0, 'P_load': 3.1085, 'H_load': 0.565181818181818, 'P': 0.87, 'P_g': 0.33, 'T': 23}\": array([0., 0., 0.]),\n",
       "             \"{'M': -2.713613633181818, 'SOC': 7, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 0}\": array([-42.09311184, -42.11459687, -42.28764424]),\n",
       "             \"{'M': 7.1910454545454545, 'SOC': 7.0, 'P_pv': 9.88, 'P_load': 2.8169999999999997, 'H_load': 0.512181818181818, 'P': 1.35, 'P_g': 0.33, 'T': 14}\": array([6.35450766, 6.16860369, 5.83472861]),\n",
       "             \"{'M': -0.5635454513636362, 'SOC': 7.0, 'P_pv': 2.12, 'P_load': 2.81133333, 'H_load': 0.511151514545455, 'P': 0.42, 'P_g': 0.33, 'T': 7}\": array([-49.75807237, -50.04534724, -50.18546285]),\n",
       "             \"{'M': 5.475204542272728, 'SOC': 7.0, 'P_pv': 8.15, 'P_load': 2.80216667, 'H_load': 0.509484849090909, 'P': 0.87, 'P_g': 0.33, 'T': 9}\": array([-41.27127208, -41.49501073, -41.67771584]),\n",
       "             \"{'M': 8.059340905909092, 'SOC': 7.0, 'P_pv': 10.8, 'P_load': 2.87116667, 'H_load': 0.522030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 11}\": array([-25.00468543, -25.25680949, -25.44115321]),\n",
       "             \"{'M': 8.176090905909092, 'SOC': 7.0, 'P_pv': 10.88, 'P_load': 2.83266667, 'H_load': 0.515030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 12}\": array([-13.84795239, -14.05487801, -14.20848862]),\n",
       "             \"{'M': 2.666954542272727, 'SOC': 7.0, 'P_pv': 6.25, 'P_load': 3.75366667, 'H_load': 0.6824848490909089, 'P': 0.87, 'P_g': 0.33, 'T': 16}\": array([16.91259824, 16.79347296, 16.62613577]),\n",
       "             \"{'M': 3.8714090877272724, 'SOC': 7.0, 'P_pv': 6.54, 'P_load': 2.79566667, 'H_load': 0.508303030909091, 'P': 0.87, 'P_g': 0.33, 'T': 8}\": array([-46.25115262, -46.47606253, -46.62054052]),\n",
       "             \"{'M': 5.592840909090908, 'SOC': 7.0, 'P_pv': 9.59, 'P_load': 4.1875, 'H_load': 0.7613636363636359, 'P': 0.87, 'P_g': 0.33, 'T': 10}\": array([-36.21309779, -36.41998463, -36.64364667]),\n",
       "             \"{'M': 7.493977272727273, 'SOC': 7.0, 'P_pv': 10.36, 'P_load': 3.0025, 'H_load': 0.545909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 13}\": array([-3.56930804, -3.76119159, -4.24977295]),\n",
       "             \"{'M': 1.5660000031818182, 'SOC': 7.0, 'P_pv': 3.82, 'P_load': 2.36133333, 'H_load': 0.429333332727273, 'P': 0.87, 'P_g': 0.33, 'T': 17}\": array([18.59033576, 18.43535823, 18.26392309]),\n",
       "             \"{'M': -2.713613633181818, 'SOC': 11, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 0}\": array([-42.04944714, -42.29626264, -42.31611972]),\n",
       "             \"{'M': -3.995886366818182, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 4.18616667, 'H_load': 0.761121212727273, 'P': 0.42, 'P_g': 0.33, 'T': 1}\": array([-43.57872995, -43.6675588 , -43.93290716]),\n",
       "             \"{'M': 5.877113639545454, 'SOC': 7.0, 'P_pv': 8.06, 'P_load': 2.28683333, 'H_load': 0.415787878181818, 'P': 1.35, 'P_g': 0.33, 'T': 15}\": array([14.43400684, 14.28469994, 14.13865077]),\n",
       "             \"{'M': 5.475204542272728, 'SOC': 11.0, 'P_pv': 8.15, 'P_load': 2.80216667, 'H_load': 0.509484849090909, 'P': 0.87, 'P_g': 0.33, 'T': 9}\": array([-41.48846374, -41.75597463, -41.85953471]),\n",
       "             \"{'M': 8.176090905909092, 'SOC': 11.0, 'P_pv': 10.88, 'P_load': 2.83266667, 'H_load': 0.515030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 12}\": array([-14.02904504, -15.44020808, -15.03726231]),\n",
       "             \"{'M': 7.1910454545454545, 'SOC': 11.0, 'P_pv': 9.88, 'P_load': 2.8169999999999997, 'H_load': 0.512181818181818, 'P': 1.35, 'P_g': 0.33, 'T': 14}\": array([ 1.58284255, -1.920781  ,  5.84088037]),\n",
       "             \"{'M': 2.666954542272727, 'SOC': 11.0, 'P_pv': 6.25, 'P_load': 3.75366667, 'H_load': 0.6824848490909089, 'P': 0.87, 'P_g': 0.33, 'T': 16}\": array([16.78915496, 16.6545166 , 16.65225043]),\n",
       "             \"{'M': 1.5660000031818182, 'SOC': 11.0, 'P_pv': 3.82, 'P_load': 2.36133333, 'H_load': 0.429333332727273, 'P': 0.87, 'P_g': 0.33, 'T': 17}\": array([18.41376827, 13.61534932, 13.53816118]),\n",
       "             \"{'M': -2.2339545422727274, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 2.34033333, 'H_load': 0.42551515090909103, 'P': 1.35, 'P_g': 0.33, 'T': 18}\": array([15.73198413, 15.57190549, 15.39963451]),\n",
       "             \"{'M': 3.8714090877272724, 'SOC': 11.0, 'P_pv': 6.54, 'P_load': 2.79566667, 'H_load': 0.508303030909091, 'P': 0.87, 'P_g': 0.33, 'T': 8}\": array([-46.39589599, -46.75215367, -46.74516341]),\n",
       "             \"{'M': 5.592840909090908, 'SOC': 11.0, 'P_pv': 9.59, 'P_load': 4.1875, 'H_load': 0.7613636363636359, 'P': 0.87, 'P_g': 0.33, 'T': 10}\": array([-36.43908139, -36.76106533, -36.67690709]),\n",
       "             \"{'M': 7.493977272727273, 'SOC': 11.0, 'P_pv': 10.36, 'P_load': 3.0025, 'H_load': 0.545909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 13}\": array([-3.69698427, -6.53360188, -8.30906502]),\n",
       "             \"{'M': 5.877113639545454, 'SOC': 11.0, 'P_pv': 8.06, 'P_load': 2.28683333, 'H_load': 0.415787878181818, 'P': 1.35, 'P_g': 0.33, 'T': 15}\": array([10.31836688, 10.23968216, 14.14680824]),\n",
       "             \"{'M': -2.2339545422727274, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 2.34033333, 'H_load': 0.42551515090909103, 'P': 1.35, 'P_g': 0.33, 'T': 18}\": array([15.55863759,  9.4234947 ,  7.47460998]),\n",
       "             \"{'M': -2.1572727272727272, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 2.26, 'H_load': 0.410909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 19}\": array([12.96552258, 12.80531653, 12.62027778]),\n",
       "             \"{'M': 8.059340905909092, 'SOC': 11.0, 'P_pv': 10.8, 'P_load': 2.87116667, 'H_load': 0.522030303636364, 'P': 1.35, 'P_g': 0.33, 'T': 11}\": array([-25.31521549, -25.5630496 , -25.54111423]),\n",
       "             \"{'M': -4.1204545486363635, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 4.31666667, 'H_load': 0.784848485454545, 'P': 0.42, 'P_g': 0.33, 'T': 2}\": array([-45.09216233, -45.40681898, -45.61973923]),\n",
       "             \"{'M': -2.1927500031818186, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 2.29716667, 'H_load': 0.41766666727272705, 'P': 0.87, 'P_g': 0.33, 'T': 22}\": array([2.24966622, 2.24707422, 2.24363796]),\n",
       "             \"{'M': -2.9672045454545453, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 3.1085, 'H_load': 0.565181818181818, 'P': 0.87, 'P_g': 0.33, 'T': 23}\": array([0., 0., 0.]),\n",
       "             \"{'M': -3.6769090909090907, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 3.852, 'H_load': 0.700363636363636, 'P': 0.42, 'P_g': 0.33, 'T': 4}\": array([-47.43968195, -47.68625078, -47.83720588]),\n",
       "             \"{'M': -2.7007272695454545, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 2.82933333, 'H_load': 0.514424241818182, 'P': 0.42, 'P_g': 0.33, 'T': 6}\": array([-49.74575269, -49.93058015, -50.21543582]),\n",
       "             \"{'M': -0.5635454513636362, 'SOC': 11.0, 'P_pv': 2.12, 'P_load': 2.81133333, 'H_load': 0.511151514545455, 'P': 0.42, 'P_g': 0.33, 'T': 7}\": array([-50.08518863, -50.33259536, -50.30089631]),\n",
       "             \"{'M': -3.4527500031818184, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 3.61716667, 'H_load': 0.657666667272727, 'P': 1.35, 'P_g': 0.33, 'T': 20}\": array([8.43185141, 8.28820888, 8.11019721]),\n",
       "             \"{'M': -4.1204545486363635, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 4.31666667, 'H_load': 0.784848485454545, 'P': 0.42, 'P_g': 0.33, 'T': 2}\": array([-45.37403454, -45.65874351, -45.64465768]),\n",
       "             \"{'M': -2.713613633181818, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 3}\": array([-46.03646164, -46.22055072, -46.50564656]),\n",
       "             \"{'M': -3.995886366818182, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 4.18616667, 'H_load': 0.761121212727273, 'P': 0.42, 'P_g': 0.33, 'T': 1}\": array([-43.79897533, -44.15819175, -44.11852235]),\n",
       "             \"{'M': -3.5461363636363634, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 3.715, 'H_load': 0.6754545454545461, 'P': 1.35, 'P_g': 0.33, 'T': 21}\": array([3.93823405, 3.75471953, 3.73315635]),\n",
       "             \"{'M': -2.1572727272727272, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 2.26, 'H_load': 0.410909090909091, 'P': 1.35, 'P_g': 0.33, 'T': 19}\": array([12.80255163,  7.71431091,  2.5257964 ]),\n",
       "             \"{'M': -3.6769090909090907, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 3.852, 'H_load': 0.700363636363636, 'P': 0.42, 'P_g': 0.33, 'T': 4}\": array([-47.67721795, -47.8829646 , -47.91707246]),\n",
       "             \"{'M': -4.128568185, 'SOC': 7.0, 'P_pv': 0.0, 'P_load': 4.32516667, 'H_load': 0.78639394, 'P': 0.42, 'P_g': 0.33, 'T': 5}\": array([-48.88079318, -49.13743845, -49.30986717]),\n",
       "             \"{'M': -2.7007272695454545, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 2.82933333, 'H_load': 0.514424241818182, 'P': 0.42, 'P_g': 0.33, 'T': 6}\": array([-49.96839194, -50.28273014, -50.28416804]),\n",
       "             \"{'M': -4.128568185, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 4.32516667, 'H_load': 0.78639394, 'P': 0.42, 'P_g': 0.33, 'T': 5}\": array([-49.15142928, -49.37760114, -49.39506202]),\n",
       "             \"{'M': -3.5461363636363634, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 3.715, 'H_load': 0.6754545454545461, 'P': 1.35, 'P_g': 0.33, 'T': 21}\": array([3.74293741, 1.75944819, 2.1076651 ]),\n",
       "             \"{'M': -3.4527500031818184, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 3.61716667, 'H_load': 0.657666667272727, 'P': 1.35, 'P_g': 0.33, 'T': 20}\": array([8.29282115, 3.91689885, 2.91813743]),\n",
       "             \"{'M': -2.713613633181818, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 2.84283333, 'H_load': 0.5168787872727271, 'P': 0.42, 'P_g': 0.33, 'T': 3}\": array([-46.30517087, -46.50442303, -46.4688858 ]),\n",
       "             \"{'M': -2.9672045454545453, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 3.1085, 'H_load': 0.565181818181818, 'P': 0.87, 'P_g': 0.33, 'T': 23}\": array([0., 0., 0.]),\n",
       "             \"{'M': -2.1927500031818186, 'SOC': 11.0, 'P_pv': 0.0, 'P_load': 2.29716667, 'H_load': 0.41766666727272705, 'P': 0.87, 'P_g': 0.33, 'T': 22}\": array([2.24364134, 1.50844267, 0.80770966])})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player=Player()\n",
    "player.Qlearning(70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3267a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep_reward -42.209813169818176\n",
      "episode [(0, 1.5077022742636366), (0, 1.4794209102272724), (0, 0.8807177257363636), (0, 1.3737318183818181), (1, 1.5028786376999999), (1, 0.7747954530090908), (0, -0.033070910227272904), (0, -3.5368059061227273), (0, -4.931167951977273), (1, -5.03390159110909), (0, -11.231360222977276), (1, -11.209992723177274), (0, -10.38682931838182), (0, -9.888061363636364), (0, -8.103123413386363), (0, -2.4574604515772727), (1, -1.5876400029681819), (0, 2.774158632268182), (0, 2.7718981820181816), (0, 4.525612504295455), (1, 4.57025409070909), (0, 1.584792502768182), (1, 2.443637954345454)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-42.209813169818176"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9140573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pv     pload     hload    pg    pt\n",
      "0    0.00  2.842833  0.516879  0.33  0.42\n",
      "1    0.00  4.186167  0.761121  0.33  0.42\n",
      "2    0.00  4.316667  0.784848  0.33  0.42\n",
      "3    0.00  2.842833  0.516879  0.33  0.42\n",
      "4    0.00  3.852000  0.700364  0.33  0.42\n",
      "5    0.00  4.325167  0.786394  0.33  0.42\n",
      "6    0.00  2.829333  0.514424  0.33  0.42\n",
      "7    2.12  2.811333  0.511152  0.33  0.42\n",
      "8    6.54  2.795667  0.508303  0.33  0.87\n",
      "9    8.15  2.802167  0.509485  0.33  0.87\n",
      "10   9.59  4.187500  0.761364  0.33  0.87\n",
      "11  10.80  2.871167  0.522030  0.33  1.35\n",
      "12  10.88  2.832667  0.515030  0.33  1.35\n",
      "13  10.36  3.002500  0.545909  0.33  1.35\n",
      "14   9.88  2.817000  0.512182  0.33  1.35\n",
      "15   8.06  2.286833  0.415788  0.33  1.35\n",
      "16   6.25  3.753667  0.682485  0.33  0.87\n",
      "17   3.82  2.361333  0.429333  0.33  0.87\n",
      "18   0.00  2.340333  0.425515  0.33  1.35\n",
      "19   0.00  2.260000  0.410909  0.33  1.35\n",
      "20   0.00  3.617167  0.657667  0.33  1.35\n",
      "21   0.00  3.715000  0.675455  0.33  1.35\n",
      "22   0.00  2.297167  0.417667  0.33  0.87\n",
      "23   0.00  3.108500  0.565182  0.33  0.87\n",
      "P_pv [ 0.    0.    0.    0.    0.    0.    0.    2.12  6.54  8.15  9.59 10.8\n",
      " 10.88 10.36  9.88  8.06  6.25  3.82  0.    0.    0.    0.    0.    0.  ]\n",
      "P_load [2.84283333 4.18616667 4.31666667 2.84283333 3.852      4.32516667\n",
      " 2.82933333 2.81133333 2.79566667 2.80216667 4.1875     2.87116667\n",
      " 2.83266667 3.0025     2.817      2.28683333 3.75366667 2.36133333\n",
      " 2.34033333 2.26       3.61716667 3.715      2.29716667 3.1085    ]\n",
      "H_load [0.51687879 0.76112121 0.78484849 0.51687879 0.70036364 0.78639394\n",
      " 0.51442424 0.51115151 0.50830303 0.50948485 0.76136364 0.5220303\n",
      " 0.5150303  0.54590909 0.51218182 0.41578788 0.68248485 0.42933333\n",
      " 0.42551515 0.41090909 0.65766667 0.67545455 0.41766667 0.56518182]\n",
      "P [0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.87 0.87 0.87 1.35 1.35 1.35\n",
      " 1.35 1.35 0.87 0.87 1.35 1.35 1.35 1.35 0.87 0.87]\n",
      "P_g [0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33\n",
      " 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33 0.33]\n",
      "V_chp [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def csv_statis(): \n",
    "    ##########读取csv中的数据统计状态数########\n",
    "    df = pd.read_csv('qlearning.csv')\n",
    "    return df\n",
    "df=csv_statis()\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "##########统计状态##############\n",
    "colos=['pv','pload','hload','pg','pt']\n",
    "state_=df[colos]\n",
    "print(state_)\n",
    "P_pv = df['pv']\n",
    "P_pv = np.array(P_pv.tolist())\n",
    "print('P_pv',P_pv)\n",
    "P_load = df['pload']\n",
    "P_load = np.array(P_load.tolist())\n",
    "print('P_load',P_load)\n",
    "H_load = df['hload']\n",
    "H_load = np.array(H_load.tolist())\n",
    "print('H_load',H_load)\n",
    "P = df['pt']\n",
    "P = np.array(P.tolist())\n",
    "print('P',P)\n",
    "P_g = df['pg']\n",
    "P_g = np.array(P_g.tolist())\n",
    "print('P_g',P_g)\n",
    "V_chp = np.zeros((24,))\n",
    "print('V_chp',V_chp)\n",
    "SOC = np.zeros((24,))\n",
    "p_ess = np.zeros((24,))\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "C_cs = 0.1\n",
    "n_chp = 0.5\n",
    "q_NG = 0.5\n",
    "def reset():\n",
    "    ##########环境初始化##############33\n",
    "    state={\n",
    "          'M':0,\n",
    "          'SOC':0,\n",
    "          'P_pv':0,\n",
    "          'P_load':0,\n",
    "          'H_load':0,\n",
    "          'P':0,\n",
    "          'P_g':0,\n",
    "           'T':0\n",
    "    }\n",
    "    \n",
    "    state['SOC'] = random.randint(0,2)*4+3\n",
    "    state['P_pv'] = P_pv[0]\n",
    "    state['P_load'] = P_load[0]\n",
    "    state['H_load'] = H_load[0]\n",
    "    state['P'] = P[0]\n",
    "    state['P_g'] = P_g[0]\n",
    "    \n",
    "    V_chp[0] = H_load[0]/(1 - n_chp)*q_NG\n",
    "    \n",
    "    P_chp = V_chp[0]*q_NG*n_chp\n",
    "\n",
    "    state['M'] = P_pv[0] + P_chp - P_load[0]\n",
    "    \n",
    "    SOC[0] = state['SOC']\n",
    "    \n",
    "    state['T'] = 0\n",
    "    \n",
    "    return str(state)\n",
    "def step(state,action,T):\n",
    "    #############env 的 动作部分，按照文档#############\n",
    "    reward = 0\n",
    "    next_state={\n",
    "      'M':0,\n",
    "      'SOC':0,\n",
    "      'P_pv':0,\n",
    "      'P_load':0,\n",
    "      'H_load':0,\n",
    "      'P':0,\n",
    "      'P_g':0,\n",
    "    'T':0}\n",
    "    \n",
    "    \n",
    "    T=T+1\n",
    "    \n",
    "    \n",
    "    SOC[T] = SOC[T-1] + (action-1)*4\n",
    "    \n",
    "    if SOC[T] > 12:\n",
    "        SOC[T] = 11\n",
    "        reward = reward -100\n",
    "    if SOC[T] < 3:\n",
    "        SOC[T] = 3\n",
    "        reward = reward -100\n",
    "    \n",
    "    V_chp[T] = H_load[T]/(1 - n_chp)*q_NG\n",
    "    \n",
    "    P_chp = V_chp[T]*q_NG*n_chp\n",
    "    \n",
    "    p_ess[T] = (action-1)*4\n",
    "    \n",
    "    M = P_pv[T] + P_chp - P_load[T]\n",
    "    \n",
    "    D = P[T]*M\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        C= P_g[t]*V_chp[t]+C_cs*p_ess[t]\n",
    "    \n",
    "    reward = reward -(C + D)\n",
    "    ################fixed_state##############33\n",
    "    next_state['P_pv'] = P_pv[T]\n",
    "    next_state['P_load'] = P_load[T]\n",
    "    next_state['H_load'] = H_load[T]\n",
    "    next_state['P'] = P[T]\n",
    "    next_state['P_g'] = P_g[T]\n",
    "    ###################################\n",
    "    V_chp[T] = H_load[T]/(1 - n_chp)*q_NG\n",
    "    \n",
    "    P_chp = V_chp[T]*q_NG*n_chp\n",
    "    \n",
    "    next_state['M'] = P_pv[T] + P_chp - P_load[T]\n",
    "    \n",
    "    next_state['SOC'] = SOC[T]\n",
    "    \n",
    "    next_state['T'] = T\n",
    "        \n",
    "    if T==23:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    return reward,str(next_state),T,done\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "LR = 0.1\n",
    "class Player:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        return\n",
    "    def reset(self):\n",
    "        reset()\n",
    "        self.greedy = 0.1\n",
    "        return\n",
    "    def soft_max_behavior_policy(self,Q,state):\n",
    "        ############波尔兹曼策略############\n",
    "        t = np.exp(Q[state])\n",
    "        a = np.exp(Q[state]) / np.sum(t, axis=0)\n",
    "        sample = np.random.uniform(0, 1)\n",
    "        if sample <= a[0]:\n",
    "            \n",
    "            act = 0\n",
    "        \n",
    "        elif sample >= a[0] and sample <=a[0]+a[1]:\n",
    "            \n",
    "            act = 1\n",
    "        \n",
    "        elif sample > a[0]+a[1]:\n",
    "            \n",
    "            act = 2\n",
    "        \n",
    "        return act\n",
    "    \n",
    "    \n",
    "    def behavior_policy(self,Q,state):\n",
    "        ##########greedy 策略#############\n",
    "        sample = np.random.uniform(0, 1)\n",
    "        if sample > self.greedy: \n",
    "            act = np.argmax(Q[state])\n",
    "        else:\n",
    "            act = np.random.randint(0, 3)\n",
    "        return act\n",
    "    def target_policy(self,state,Q):\n",
    "        value = Q[state]\n",
    "        return value\n",
    "    def Qlearning_greedy(self,num_episodes, max_time=100, discount_factor=1.0):\n",
    "        ###########使用greedy的qlearning#############\n",
    "        #########初始化Q值############\n",
    "        self.Q = defaultdict(lambda:np.zeros(3))\n",
    "        q_value = []\n",
    "        xias = []\n",
    "        for i_episode in range(0, num_episodes+1):\n",
    "            if i_episode % 1000 == 0:\n",
    "                #####每间隔1000个episode进行仿真一次统计该轮reward###########\n",
    "                print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                qq=self.simulate_greedy()\n",
    "                print(qq)\n",
    "                q_value.append(qq)\n",
    "                xias.append(i_episode)\n",
    "            episode = []\n",
    "            #####3初始化状态#############3\n",
    "            t=0\n",
    "            state=reset()\n",
    "            while(1):\n",
    "                ######根据策略进行决策##########33\n",
    "                action = self.behavior_policy(self.Q,state)\n",
    "                #reward,next_state,done = env(action,state)\n",
    "                #######执行动作#############333\n",
    "                reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "\n",
    "                episode.append((state, action, reward))\n",
    "                #print (next_state)\n",
    "                #print('argmax',np.argmax(Q[next_state]),'\\n')\n",
    "                ##########Q_learning 更新 q_value###############3\n",
    "                self.Q[state][action] = self.Q[state][action] + LR*(reward + discount_factor*self.Q[next_state][np.argmax(self.Q[next_state])]-self.Q[state][action])\n",
    "                state = next_state\n",
    "                t = next_t\n",
    "                if done == True:\n",
    "                    ########经过了24个小时一轮调度完成##############\n",
    "                    break\n",
    "            \n",
    "        print(len(self.Q))\n",
    "        #self.Q=Q\n",
    "        print(q_value)\n",
    "        ########绘图################3\n",
    "        plt.plot(xias,q_value)\n",
    "        plt.show\n",
    "        #print(np.argmax(Q[state]))\n",
    "        return self.Q\n",
    "    def Qlearning_soft(self,num_episodes, max_time=100, discount_factor=1.0):\n",
    "        #########使用波尔兹曼策略的greedy##############\n",
    "        self.Q = defaultdict(lambda:np.zeros(3))\n",
    "        q_value = []\n",
    "        xias = []\n",
    "        for i_episode in range(0, num_episodes+1):\n",
    "            if i_episode % 1000 == 0:\n",
    "                print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                qq=self.simulate_soft()\n",
    "                q_value.append(qq)\n",
    "                xias.append(i_episode)\n",
    "            episode = []\n",
    "            t=0\n",
    "            state=reset()\n",
    "            while(1):\n",
    "                action = self.soft_max_behavior_policy(self.Q,state)\n",
    "                #reward,next_state,done = env(action,state)\n",
    "                \n",
    "                reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "\n",
    "                episode.append((state, action, reward))\n",
    "                #print (next_state)\n",
    "                #print('argmax',np.argmax(Q[next_state]),'\\n')\n",
    "                self.Q[state][action] = self.Q[state][action] + LR*(reward + discount_factor*self.Q[next_state][np.argmax(self.Q[next_state])]-self.Q[state][action])\n",
    "                state = next_state\n",
    "                t = next_t\n",
    "                if done == True:\n",
    "                    break\n",
    "            \n",
    "        print(len(self.Q))\n",
    "        #self.Q=Q\n",
    "        plt.plot(xias,q_value)\n",
    "        plt.show\n",
    "        #print(np.argmax(Q[state]))\n",
    "        return self.Q\n",
    "    def init_Q(self,Q):\n",
    "        for state in range(7):\n",
    "            state = state -3\n",
    "            Q[state]=[0.0,0.0,0.0]\n",
    "        return Q\n",
    "    def simulate_greedy(self):\n",
    "        #######greedy进行仿真##########\n",
    "        state=reset()\n",
    "        t=0\n",
    "        episode=[]\n",
    "        ep_reward=0\n",
    "        while(1):\n",
    "            action = self.behavior_policy(self.Q,state)\n",
    "            #reward,next_state,done = env(action,state)\n",
    "\n",
    "            reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "            episode.append((action, reward))\n",
    "            state = next_state\n",
    "            t = next_t\n",
    "            ep_reward = ep_reward + reward\n",
    "            if done == True:\n",
    "                break\n",
    "        return ep_reward\n",
    "    def simulate_soft(self):\n",
    "        #######波尔兹曼仿真#################\n",
    "        state=reset()\n",
    "        t=0\n",
    "        episode=[]\n",
    "        ep_reward=0\n",
    "        while(1):\n",
    "            action = self.soft_max_behavior_policy(self.Q,state)\n",
    "            #reward,next_state,done = env(action,state)\n",
    "\n",
    "            reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "            episode.append((action, reward))\n",
    "            state = next_state\n",
    "            t = next_t\n",
    "            ep_reward = ep_reward + reward\n",
    "            if done == True:\n",
    "                break\n",
    "        #print('ep_reward',ep_reward)\n",
    "        #print('episode',episode)\n",
    "        return ep_reward\n",
    "    def simulate_print(self):\n",
    "        ##########仿真并输出决策##################3\n",
    "        state=reset()\n",
    "        t=0\n",
    "        episode=[]\n",
    "        ep_reward=0\n",
    "        while(1):\n",
    "            action = self.soft_max_behavior_policy(self.Q,state)\n",
    "            #reward,next_state,done = env(action,state)\n",
    "\n",
    "            reward,next_state,next_t,done=step(state=state,action=action,T=t)\n",
    "            episode.append((action, reward))\n",
    "            state = next_state\n",
    "            t = next_t\n",
    "            ep_reward = ep_reward + reward\n",
    "            if done == True:\n",
    "                break\n",
    "        print('ep_reward',ep_reward)\n",
    "        print('episode',episode)\n",
    "        return ep_reward\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b9e82c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/10000.-2132.8098131698184\n",
      "Episode 1000/10000.-41.60981316981818\n",
      "Episode 2000/10000.-41.60981316981819\n",
      "Episode 3000/10000.-40.809813169818185\n",
      "Episode 4000/10000.-41.20981316981818\n",
      "Episode 5000/10000.-41.60981316981819\n",
      "Episode 6000/10000.-41.60981316981819\n",
      "Episode 7000/10000.-41.20981316981818\n",
      "Episode 8000/10000.-141.6098131698182\n",
      "Episode 9000/10000.-41.60981316981819\n",
      "Episode 10000/10000.-140.80981316981817\n",
      "72\n",
      "[-2132.8098131698184, -41.60981316981818, -41.60981316981819, -40.809813169818185, -41.20981316981818, -41.60981316981819, -41.60981316981819, -41.20981316981818, -141.6098131698182, -41.60981316981819, -140.80981316981817]\n",
      "Episode 10000/10000.72\n",
      "ep_reward -41.609813169818175\n",
      "episode [(1, 1.5077022742636366), (0, 1.4794209102272724), (1, 1.2807177257363638), (0, 1.3737318183818181), (1, 1.9028786377), (1, 0.8747954530090909), (1, 0.0669290897727271), (1, -3.5368059061227273), (1, -4.931167951977273), (1, -5.03390159110909), (1, -11.131360222977277), (1, -11.209992723177274), (1, -10.28682931838182), (1, -9.888061363636364), (2, -8.103123413386363), (1, -2.8574604515772726), (1, -1.5876400029681819), (0, 2.8741586322681822), (2, 3.1718981820181815), (2, 4.1256125042954555), (1, 4.170254090709091), (1, 1.684792502768182), (0, 2.443637954345454)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-41.609813169818175"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "player=Player()\n",
    "_=player.Qlearning_greedy(10000)\n",
    "_=player.Qlearning_soft(10000)\n",
    "player.simulate_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea8f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
